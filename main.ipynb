{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e32d9bb",
   "metadata": {},
   "source": [
    "# NLP Mental Health Chatbot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50bca21",
   "metadata": {},
   "source": [
    "- Emotion Detection: Fine-tuned RoBERTa\n",
    "- Intent Detection: Sentence-BERT + Semantic Matching\n",
    "- Response Generation: LLaMA3 via Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68e8787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2f119aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment to suppress warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"MallocStackLogging\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a322616",
   "metadata": {},
   "source": [
    "## Load Fine-Tuned RoBERTa Emotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e73f286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fine-tuned RoBERTa emotion classifier.\n"
     ]
    }
   ],
   "source": [
    "emotion_model = RobertaForSequenceClassification.from_pretrained(\"saved_roberta_emotion_model\")\n",
    "emotion_tokenizer = RobertaTokenizer.from_pretrained(\"saved_roberta_emotion_model\")\n",
    "mlb_classes = joblib.load(\"emotion_labels.pkl\")\n",
    "print(\"Loaded fine-tuned RoBERTa emotion classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a0001",
   "metadata": {},
   "source": [
    "## Load Sentence-BERT for Intent Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ba16361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadied intent patterns from KB.json.\n",
      "Loading Sentence-BERT model for intent classification...\n"
     ]
    }
   ],
   "source": [
    "with open(\"KB.json\", \"r\") as f:\n",
    "    kb = json.load(f)\n",
    "print(\"Loadied intent patterns from KB.json.\")\n",
    "\n",
    "intent_patterns = []\n",
    "intent_tags = []\n",
    "for intent in kb[\"intents\"]:\n",
    "    tag = intent[\"tag\"]\n",
    "    for pattern in intent.get(\"patterns\", []):\n",
    "        if pattern.strip():\n",
    "            intent_patterns.append(pattern.strip())\n",
    "            intent_tags.append(tag)\n",
    "\n",
    "print(\"Loading Sentence-BERT model for intent classification...\")\n",
    "intent_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "intent_embeddings = intent_encoder.encode(intent_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950fc91",
   "metadata": {},
   "source": [
    "## Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef2b2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_emotion_roberta(text):\n",
    "    inputs = emotion_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = emotion_model(**inputs).logits\n",
    "    probs = torch.sigmoid(logits)[0].cpu().numpy()\n",
    "\n",
    "    # print(\"Raw Emotion Probabilities:\")\n",
    "    # for i, p in enumerate(probs):\n",
    "    #     print(f\"{mlb_classes[i]}: {p:.3f}\")\n",
    "\n",
    "    threshold = 0.35  # Lowered threshold to capture more subtle emotions\n",
    "    top_labels = [mlb_classes[i] for i, p in enumerate(probs) if p > threshold]\n",
    "\n",
    "    if not top_labels:\n",
    "        top_labels = [mlb_classes[int(np.argmax(probs))]]  # fallback if no emotion passes threshold\n",
    "\n",
    "    return top_labels  # fallback if no score > 0.5\n",
    "\n",
    "def detect_intent(text, top_k=3):\n",
    "    \"\"\"Use Sentence-BERT + cosine similarity to detect closest intent.\"\"\"\n",
    "    input_embedding = intent_encoder.encode([text])\n",
    "    sims = cosine_similarity(input_embedding, intent_embeddings)[0]\n",
    "    top_indices = sims.argsort()[-top_k:][::-1]\n",
    "    top_matches = [(intent_tags[i], intent_patterns[i], sims[i]) for i in top_indices]\n",
    "    print(\"Top intent matches:\")\n",
    "    # for tag, pattern, score in top_matches:\n",
    "    #     print(f\" - {tag}: '{pattern}' ({score:.2f})\")\n",
    "    return top_matches[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bbc2c",
   "metadata": {},
   "source": [
    "### Generate response from llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41ca11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def query_llama(prompt):\n",
    "    try:\n",
    "        # Send the request to Ollama\n",
    "        response = requests.post(\n",
    "            OLLAMA_API_URL,\n",
    "            json={\n",
    "                \"model\": \"llama3\",\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            }\n",
    "        )\n",
    "        # Parse the response\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            response_text = result[\"response\"].strip()\n",
    "            # Remove extra line spaces\n",
    "            cleaned_response = ' '.join(response_text.splitlines())\n",
    "            return cleaned_response \n",
    "        else:\n",
    "            print(f\"Error: {response.text}\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60747b6",
   "metadata": {},
   "source": [
    "### Pipeline: Detect intent + emotion â†’ generate response using KB and LLaMA3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab214e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input, history=[]):\n",
    "    emotions = detect_emotion_roberta(user_input)\n",
    "    intent = detect_intent(user_input)\n",
    "    \n",
    "    \n",
    "    print(f\"Detected Emotion(s): {emotions}\")\n",
    "    print(f\"Detected Intent: {intent}\")\n",
    "\n",
    "    # Try rule-based KB response first\n",
    "    kb_response = None\n",
    "    for entry in kb[\"intents\"]:\n",
    "        if entry[\"tag\"] == intent and entry.get(\"responses\"):\n",
    "            kb_response = entry[\"responses\"]\n",
    "            break\n",
    "    \n",
    "    if history:\n",
    "        prompt = f\"Please act as a mental health chatbot. The user says {user_input} and the predicted emotions from roberta model are {emotions} and the predicted intent from sentence bert is {intent}. The user's previous messages are {history}. Please respond in a supportive and empathetic manner.\"\n",
    "    else:\n",
    "        prompt = f\"Please act as a mental health chatbot. The user says {user_input} and the predicted emotions from roberta model are {emotions} and the predicted intent from sentence bert is {intent}. Please respond in a supportive and empathetic manner.\"\n",
    "\n",
    "    # Add to history\n",
    "    history.append(user_input)\n",
    "    \n",
    "    if kb_response:\n",
    "        selected_response = kb_response[0] if isinstance(kb_response, list) else kb_response\n",
    "        bot_response = query_llama(prompt)\n",
    "        return f\"{selected_response}{bot_response}\"\n",
    "    else:\n",
    "        return query_llama(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c198242",
   "metadata": {},
   "source": [
    "## Let's chat with the Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4a787e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Mental Health Chatbot ðŸ’¬ \n",
      "Please enter your prompt \n",
      "Type 'quit' to exit\n",
      "\n",
      "Top intent matches:\n",
      "Detected Emotion(s): ['surprised']\n",
      "Detected Intent: problem\n",
      "Bot: I'm sorry to hear that. It sounds like you're going through a tough time.Oh, sweetheart, I'm so sorry to hear that you're having a tough time with your friend. It sounds like things didn't go as planned, and you're feeling a mix of emotions.  First and foremost, let me acknowledge that it's okay to feel surprised - life can be unpredictable, and sometimes we're taken aback by unexpected events. And it's completely normal to want to talk about the problem with your friend (or maybe just need someone to listen).  Can you tell me more about what happened? I'm here to listen without judgment, and I want to understand what you're going through. Sometimes talking about our feelings can help us process and make sense of things.  Remember, you're not alone in this. I'm here for you, and we can work through this together.\n",
      "\n",
      "Top intent matches:\n",
      "Detected Emotion(s): ['surprised']\n",
      "Detected Intent: default\n",
      "Bot: Oh I see. Tell me moreI'm so sorry to hear that you're having a tough day, especially because of something that happened with your friend. It sounds like you're feeling pretty surprised by this turn of events, and I can imagine how frustrating and disappointing it must be.  Can you tell me more about what happened? Sometimes talking about it can help process your emotions and gain some perspective. I'm here to listen and offer support without judgment. Remember that relationships with friends are important for our well-being, so let's work together to explore ways to strengthen that bond or find a way forward if things have taken a rough turn.  What do you think might have contributed to this mishap? Was it something specific your friend did or said, or was it more of an unexpected circumstance? I'm here to help you sort through your feelings and offer any guidance I can.\n",
      "\n",
      "Top intent matches:\n",
      "Detected Emotion(s): ['surprised']\n",
      "Detected Intent: sad\n",
      "Bot: I'm sorry to hear that. I'm here for you. Talking about it might help. So, tell me why do you think you're feeling this way?I'm so sorry to hear that you're feeling sad today. It sounds like you've been going through a tough time, especially with the mishap with your friend. I can only imagine how challenging it must be for you.  It's completely understandable that you'd feel upset given the situation. Building relationships can be difficult, and when things don't go as planned, it can be even more painful.  Can you tell me a bit more about what happened with your friend? Sometimes talking about it can help process your emotions and gain some clarity. I'm here to listen without judgment and offer any support I can.  Remember that you're not alone in this feeling. It's okay to feel sad, and it doesn't mean you're weak or flawed. We all experience a range of emotions, and sadness is a natural part of life.  What do you think might help you feel better today? Do you have anything that brings you joy or comfort?\n",
      "\n",
      "Bot: Take care! ðŸ’™\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the Mental Health Chatbot ðŸ’¬ \\nPlease enter your prompt \\nType 'quit' to exit\\n\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"Bot: Take care! ðŸ’™\")\n",
    "            break\n",
    "        response = chat(user_input)\n",
    "        print(f\"Bot: {response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
