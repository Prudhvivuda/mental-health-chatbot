{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1dc4602-0490-4aa3-9d8f-e26061dc6db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shrivarshininarayanan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # punctuation\n",
    "    text = text.lower().strip()\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Load datasets\n",
    "go_emotions = pd.read_csv(\"go_emotions_dataset.csv\")\n",
    "emotion_69k = pd.read_csv(\"emotion-emotion_69k.csv\")\n",
    "reddit = pd.read_csv(\"reddit_text-davinci-002.csv\")\n",
    "\n",
    "# Apply cleaning# Apply cleaning to each dataset using the correct column names\n",
    "go_emotions[\"clean_text\"] = go_emotions[\"text\"].astype(str).apply(clean_text)\n",
    "\n",
    "emotion_69k[\"clean_text\"] = emotion_69k[\"Situation\"].astype(str).apply(clean_text)\n",
    "\n",
    "reddit[\"clean_text\"] = reddit[\"prompt\"].astype(str).apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388a45d9-6b3f-48e2-b14c-ef21286739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_69k[\"emotion\"] = emotion_69k[\"emotion\"].fillna(\"unknown\")\n",
    "emotion_69k[\"labels\"] = emotion_69k[\"emotion\"].apply(lambda x: x.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a885cda-29ca-4b72-b43a-4ad41e61c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37054         [content]\n",
      "15618    [anticipating]\n",
      "44316       [confident]\n",
      "10562        [prepared]\n",
      "16123           [angry]\n",
      "Name: labels, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(emotion_69k[\"labels\"].sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b8b7fe9-7db6-4651-a065-f19773fa039d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ca7f69bdc74e5a915b35866a620661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16160' max='16160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16160/16160 11:51:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.101302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.101300</td>\n",
       "      <td>0.101037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16160, training_loss=0.1021575416668807, metrics={'train_runtime': 42679.439, 'train_samples_per_second': 3.029, 'train_steps_per_second': 0.379, 'total_flos': 3091861183034304.0, 'train_loss': 0.1021575416668807, 'epoch': 2.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datasets import Dataset, Features, Sequence, Value\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Prepare labels\n",
    "emotion_69k[\"labels\"] = emotion_69k[\"emotion\"].apply(lambda x: x.split(',') if isinstance(x, str) else [\"unknown\"])\n",
    "mlb = MultiLabelBinarizer()\n",
    "label_matrix = mlb.fit_transform(emotion_69k[\"labels\"]).astype(np.float32)\n",
    "\n",
    "# Explicitly define the dataset structure\n",
    "features = Features({\n",
    "    'clean_text': Value('string'),\n",
    "    'labels': Sequence(Value(dtype='float32'))\n",
    "})\n",
    "\n",
    "# Build dataset with proper float32 labels\n",
    "dataset = Dataset.from_dict({\n",
    "    \"clean_text\": emotion_69k[\"clean_text\"].tolist(),\n",
    "    \"labels\": label_matrix.tolist()\n",
    "}, features=features)\n",
    "\n",
    "# Tokenize\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"clean_text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Format for PyTorch\n",
    "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Load model and setup\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=label_matrix.shape[1])\n",
    "model.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "# Training config\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./emotion_roberta\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized,\n",
    "    eval_dataset=tokenized,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "565b4599-455d-4765-821b-59e15d6448dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11165' max='8080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8080/8080 58:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.10103712975978851, 'eval_runtime': 1538.6123, 'eval_samples_per_second': 42.009, 'eval_steps_per_second': 5.251, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emotion_labels.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)\n",
    "# Save labels\n",
    "import joblib\n",
    "joblib.dump(mlb.classes_, \"emotion_labels.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5210a-fdd3-4840-98de-9f613fdf1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "preds_output = trainer.predict(tokenized)\n",
    "pred_labels = (preds_output.predictions > 0.5).astype(int)\n",
    "true_labels = np.array(preds_output.label_ids)\n",
    "\n",
    "# Evaluation report\n",
    "print(classification_report(true_labels, pred_labels, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93140a91-1299-4800-a047-539664ac97ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_roberta_emotion_model/tokenizer_config.json',\n",
       " 'saved_roberta_emotion_model/special_tokens_map.json',\n",
       " 'saved_roberta_emotion_model/vocab.json',\n",
       " 'saved_roberta_emotion_model/merges.txt',\n",
       " 'saved_roberta_emotion_model/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"saved_roberta_emotion_model\")\n",
    "tokenizer.save_pretrained(\"saved_roberta_emotion_model\")\n",
    "# from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "# model = RobertaForSequenceClassification.from_pretrained(\"saved_roberta_emotion_model\")\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"saved_roberta_emotion_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef602f0-b0eb-4ee6-a44b-08ef3fa1d2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ed84e08-0fa0-4f5c-bab7-31a261cc3c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned RoBERTa emotion classifier...\n",
      "Loading intent patterns from KB.json...\n",
      "Loading Sentence-BERT model for intent classification...\n",
      "Evaluating intent model self-match accuracy...\n",
      "Self-match intent accuracy: 99.78%\n",
      "Welcome to the Mental Health Chatbot ðŸ’¬ (type 'quit' to exit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Emotion Probabilities:\n",
      " I really killed it!: 0.000\n",
      " a boy.  I hear all these different labor stories that aren't exactly reassuring!  : 0.000\n",
      " but what I didn't know was that he was working in the next room with the door open.  He approached and asked what I had been saying.  I knew I was caught.  I was so disgusted with myself.  : 0.000\n",
      " time to jump on the motorcycle and go cruising!: 0.000\n",
      " we were in a different country: 0.000\n",
      "(: 0.000\n",
      "afraid: 0.032\n",
      "angry: 0.035\n",
      "annoyed: 0.033\n",
      "anticipating: 0.029\n",
      "anxious: 0.029\n",
      "apprehensive: 0.023\n",
      "ashamed: 0.024\n",
      "caring: 0.026\n",
      "confident: 0.029\n",
      "content: 0.027\n",
      "devastated: 0.025\n",
      "disappointed: 0.029\n",
      "disgusted: 0.027\n",
      "embarrassed: 0.029\n",
      "excited: 0.037\n",
      "faithful: 0.018\n",
      "furious: 0.029\n",
      "grateful: 0.031\n",
      "guilty: 0.030\n",
      "hopeful: 0.028\n",
      "impressed: 0.029\n",
      "jealous: 0.030\n",
      "joyful: 0.029\n",
      "lonely: 0.034\n",
      "m so mad with my brother. He stole from me and didn't think I would notice. : 0.000\n",
      "nostalgic: 0.030\n",
      "prepared: 0.028\n",
      "proud: 0.032\n",
      "sad: 0.031\n",
      "sentimental: 0.025\n",
      "surprised: 0.049\n",
      "t believe I like the show Power so much. I was never really into shows like that: 0.000\n",
      "t believe my daughter taught herself how to play the ukelele. I was amazed: 0.000\n",
      "t even like scary things: 0.000\n",
      "t think I wold like super heroes: 0.000\n",
      "terrified: 0.030\n",
      "trusting: 0.026\n",
      "unknown: 0.000\n",
      "Top intent matches:\n",
      " - greeting: 'Hi' (1.00)\n",
      " - greeting: 'Hello' (0.81)\n",
      " - greeting: 'Hi there' (0.80)\n",
      "--- Debug Info ---\n",
      "Detected Emotion(s): ['surprised']\n",
      "Detected Intent: greeting\n",
      "Using KB-based response: Hello there. Tell me how are you feeling today?\n",
      "Prompt sent to LLaMA2:\n",
      "Context:User: hiIntent: greetingEmotion(s): ['surprised']Now, respond empathetically and constructively to the last user message.\n",
      "------------------\n",
      "Calling LLaMA2 via Ollama...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(83988) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello there. Tell me how are you feeling today?The response took too long to generate. Try again.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Take care! ðŸ’™\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# NLP Mental Health Chatbot - Final Version (Based on Project Proposal)\n",
    "# Emotion Detection: Fine-tuned RoBERTa\n",
    "# Intent Detection: Sentence-BERT + Semantic Matching\n",
    "# Response Generation: LLaMA2 via Ollama\n",
    "# ======================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib\n",
    "\n",
    "# Set environment to suppress warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"MallocStackLogging\"] = \"0\"\n",
    "\n",
    "# ============ STEP 1: Load Fine-Tuned RoBERTa Emotion Model ============\n",
    "print(\"Loading fine-tuned RoBERTa emotion classifier...\")\n",
    "emotion_model = RobertaForSequenceClassification.from_pretrained(\"saved_roberta_emotion_model\")\n",
    "emotion_tokenizer = RobertaTokenizer.from_pretrained(\"saved_roberta_emotion_model\")\n",
    "mlb_classes = joblib.load(\"emotion_labels.pkl\")\n",
    "\n",
    "# ============ STEP 2: Load Sentence-BERT for Intent Detection ============\n",
    "print(\"Loading intent patterns from KB.json...\")\n",
    "with open(\"KB.json\", \"r\") as f:\n",
    "    kb = json.load(f)\n",
    "\n",
    "intent_patterns = []\n",
    "intent_tags = []\n",
    "for intent in kb[\"intents\"]:\n",
    "    tag = intent[\"tag\"]\n",
    "    for pattern in intent.get(\"patterns\", []):\n",
    "        if pattern.strip():\n",
    "            intent_patterns.append(pattern.strip())\n",
    "            intent_tags.append(tag)\n",
    "\n",
    "print(\"Loading Sentence-BERT model for intent classification...\")\n",
    "intent_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "intent_embeddings = intent_encoder.encode(intent_patterns)\n",
    "\n",
    "# Optional: Evaluate self-accuracy\n",
    "print(\"Evaluating intent model self-match accuracy...\")\n",
    "y_true = intent_tags\n",
    "y_pred = []\n",
    "for pattern in intent_patterns:\n",
    "    input_embedding = intent_encoder.encode([pattern])\n",
    "    sims = cosine_similarity(input_embedding, intent_embeddings)[0]\n",
    "    best_index = sims.argsort()[-1]\n",
    "    y_pred.append(intent_tags[best_index])\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Self-match intent accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# ============ STEP 3: Define Utility Functions ============\n",
    "\n",
    "def detect_emotion_roberta(text):\n",
    "    inputs = emotion_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = emotion_model(**inputs).logits\n",
    "    probs = torch.sigmoid(logits)[0].cpu().numpy()\n",
    "\n",
    "    # Debug print: Show emotion probabilities and mapping\n",
    "    print(\"Raw Emotion Probabilities:\")\n",
    "    for i, p in enumerate(probs):\n",
    "        print(f\"{mlb_classes[i]}: {p:.3f}\")\n",
    "\n",
    "    threshold = 0.35  # Lowered threshold to capture more subtle emotions\n",
    "    top_labels = [mlb_classes[i] for i, p in enumerate(probs) if p > threshold]\n",
    "\n",
    "    if not top_labels:\n",
    "        top_labels = [mlb_classes[int(np.argmax(probs))]]  # fallback if no emotion passes threshold\n",
    "\n",
    "    return top_labels  # fallback if no score > 0.5\n",
    "\n",
    "def detect_intent(text, top_k=3):\n",
    "    \"\"\"Use Sentence-BERT + cosine similarity to detect closest intent.\"\"\"\n",
    "    input_embedding = intent_encoder.encode([text])\n",
    "    sims = cosine_similarity(input_embedding, intent_embeddings)[0]\n",
    "    top_indices = sims.argsort()[-top_k:][::-1]\n",
    "    top_matches = [(intent_tags[i], intent_patterns[i], sims[i]) for i in top_indices]\n",
    "    print(\"Top intent matches:\")\n",
    "    for tag, pattern, score in top_matches:\n",
    "        print(f\" - {tag}: '{pattern}' ({score:.2f})\")\n",
    "    return top_matches[0][0]\n",
    "\n",
    "def llama_respond(prompt: str, model: str = \"llama2\"):\n",
    "    \"\"\"Generate a response using LLaMA2 via Ollama CLI.\"\"\"\n",
    "    try:\n",
    "        print(\"Calling LLaMA2 via Ollama...\")\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", model, prompt],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=180\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return result.stdout.strip()\n",
    "        else:\n",
    "            print(\"Ollama error:\", result.stderr)\n",
    "            return \"I'm sorry, I encountered an issue generating a response.\"\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \"The response took too long to generate. Try again.\"\n",
    "\n",
    "def generate_response(user_input, history=[]):\n",
    "    \"\"\"Pipeline: Detect intent + emotion â†’ generate response using KB and LLaMA2.\"\"\"\n",
    "    emotions = detect_emotion_roberta(user_input)\n",
    "    intent = detect_intent(user_input)\n",
    "\n",
    "    # Try rule-based KB response first\n",
    "    kb_response = None\n",
    "    for entry in kb[\"intents\"]:\n",
    "        if entry[\"tag\"] == intent and entry.get(\"responses\"):\n",
    "            kb_response = entry[\"responses\"]\n",
    "            break\n",
    "\n",
    "    # Add to history\n",
    "    history.append({\"input\": user_input, \"intent\": intent, \"emotions\": emotions})\n",
    "\n",
    "    print(\"--- Debug Info ---\")\n",
    "    print(f\"Detected Emotion(s): {emotions}\")\n",
    "    print(f\"Detected Intent: {intent}\")\n",
    "\n",
    "    # Generate LLaMA2 continuation even if KB exists\n",
    "    prompt_history = \"\".join([f\"User: {msg['input']}Intent: {msg['intent']}Emotion(s): {msg['emotions']}\"\n",
    "        for msg in history[-3:]  ])\n",
    "    prompt = (f\"Context:{prompt_history}\"f\"Now, respond empathetically and constructively to the last user message.\")\n",
    "\n",
    "    if kb_response:\n",
    "        selected_response = kb_response[0] if isinstance(kb_response, list) else kb_response\n",
    "        print(f\"Using KB-based response: {selected_response}\")\n",
    "        print(\"Prompt sent to LLaMA2:\")\n",
    "        print(prompt)\n",
    "        print(\"------------------\")\n",
    "        bot_response = llama_respond(prompt)\n",
    "        return f\"{selected_response}{bot_response}\"\n",
    "    else:\n",
    "        print(\"Prompt sent to LLaMA2:\")\n",
    "        print(prompt)\n",
    "        print(\"------------------\")\n",
    "        return llama_respond(prompt)\n",
    "\n",
    "# ============ STEP 4: CLI Chatbot ============\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the Mental Health Chatbot ðŸ’¬ (type 'quit' to exit)\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"Bot: Take care! ðŸ’™\")\n",
    "            break\n",
    "        response = generate_response(user_input)\n",
    "        print(f\"Bot: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2736e9-6eca-4974-ab8c-49a82dd5d64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbff3a-1fa3-4dfc-bb52-7b57fce51a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
