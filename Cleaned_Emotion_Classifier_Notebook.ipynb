{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dc4602-0490-4aa3-9d8f-e26061dc6db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shrivarshininarayanan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # punctuation\n",
    "    text = text.lower().strip()\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Load datasets\n",
    "go_emotions = pd.read_csv(\"go_emotions_dataset.csv\")\n",
    "emotion_69k = pd.read_csv(\"emotion-emotion_69k.csv\")\n",
    "reddit = pd.read_csv(\"reddit_text-davinci-002.csv\")\n",
    "\n",
    "# Apply cleaning# Apply cleaning to each dataset using the correct column names\n",
    "go_emotions[\"clean_text\"] = go_emotions[\"text\"].astype(str).apply(clean_text)\n",
    "\n",
    "emotion_69k[\"clean_text\"] = emotion_69k[\"Situation\"].astype(str).apply(clean_text)\n",
    "\n",
    "reddit[\"clean_text\"] = reddit[\"prompt\"].astype(str).apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388a45d9-6b3f-48e2-b14c-ef21286739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_69k[\"emotion\"] = emotion_69k[\"emotion\"].fillna(\"unknown\")\n",
    "emotion_69k[\"labels\"] = emotion_69k[\"emotion\"].apply(lambda x: x.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a885cda-29ca-4b72-b43a-4ad41e61c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26932    [devastated]\n",
      "47094     [surprised]\n",
      "29365       [annoyed]\n",
      "15267       [hopeful]\n",
      "15961       [jealous]\n",
      "Name: labels, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(emotion_69k[\"labels\"].sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8b7fe9-7db6-4651-a065-f19773fa039d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b07ec20695944d7b9baf39f20cd2c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16160' max='16160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16160/16160 14:15:03, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.039141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.022624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16160, training_loss=0.05006685788088506, metrics={'train_runtime': 51323.4191, 'train_samples_per_second': 2.519, 'train_steps_per_second': 0.315, 'total_flos': 3091861183034304.0, 'train_loss': 0.05006685788088506, 'epoch': 2.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datasets import Dataset, Features, Sequence, Value\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Prepare labels\n",
    "emotion_69k[\"labels\"] = emotion_69k[\"emotion\"].apply(lambda x: x.split(',') if isinstance(x, str) else [\"unknown\"])\n",
    "mlb = MultiLabelBinarizer()\n",
    "label_matrix = mlb.fit_transform(emotion_69k[\"labels\"]).astype(np.float32)\n",
    "\n",
    "# Explicitly define the dataset structure\n",
    "features = Features({\n",
    "    'clean_text': Value('string'),\n",
    "    'labels': Sequence(Value(dtype='float32'))\n",
    "})\n",
    "\n",
    "# Build dataset with proper float32 labels\n",
    "dataset = Dataset.from_dict({\n",
    "    \"clean_text\": emotion_69k[\"clean_text\"].tolist(),\n",
    "    \"labels\": label_matrix.tolist()\n",
    "}, features=features)\n",
    "\n",
    "# Tokenize\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"clean_text\"], padding=True, truncation=True)\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Format for PyTorch\n",
    "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Load model and setup\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=label_matrix.shape[1])\n",
    "model.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "# Training config\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./emotion_roberta\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized,\n",
    "    eval_dataset=tokenized,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "565b4599-455d-4765-821b-59e15d6448dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.022623591125011444, 'eval_runtime': 5935.2605, 'eval_samples_per_second': 10.89, 'eval_steps_per_second': 1.361, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['emotion_labels.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)\n",
    "# Save labels\n",
    "import joblib\n",
    "joblib.dump(mlb.classes_, \"emotion_labels.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1a5210a-fdd3-4840-98de-9f613fdf1871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                precision    recall  f1-score   support\n",
      "\n",
      "                                                                                                                                                                           I really killed it!       0.00      0.00      0.00         4\n",
      "                                                                                                            a boy.  I hear all these different labor stories that aren't exactly reassuring!         0.00      0.00      0.00         3\n",
      " but what I didn't know was that he was working in the next room with the door open.  He approached and asked what I had been saying.  I knew I was caught.  I was so disgusted with myself.         0.00      0.00      0.00         4\n",
      "                                                                                                                                               time to jump on the motorcycle and go cruising!       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                we were in a different country       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                             (       0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                        afraid       1.00      0.01      0.03      2094\n",
      "                                                                                                                                                                                         angry       1.00      0.00      0.00      2296\n",
      "                                                                                                                                                                                       annoyed       0.94      0.81      0.87      2213\n",
      "                                                                                                                                                                                  anticipating       0.84      0.28      0.42      2026\n",
      "                                                                                                                                                                                       anxious       0.84      0.48      0.61      2037\n",
      "                                                                                                                                                                                  apprehensive       0.92      0.73      0.81      1549\n",
      "                                                                                                                                                                                       ashamed       0.94      0.27      0.41      1694\n",
      "                                                                                                                                                                                        caring       0.95      0.92      0.93      1765\n",
      "                                                                                                                                                                                     confident       0.93      0.91      0.92      2037\n",
      "                                                                                                                                                                                       content       0.95      0.88      0.92      1903\n",
      "                                                                                                                                                                                    devastated       0.92      0.64      0.76      1856\n",
      "                                                                                                                                                                                  disappointed       0.92      0.79      0.85      1969\n",
      "                                                                                                                                                                                     disgusted       0.96      0.89      0.93      2044\n",
      "                                                                                                                                                                                   embarrassed       0.94      0.93      0.93      1844\n",
      "                                                                                                                                                                                       excited       0.86      0.52      0.65      2465\n",
      "                                                                                                                                                                                      faithful       0.96      0.84      0.90      1283\n",
      "                                                                                                                                                                                       furious       0.92      0.04      0.07      2045\n",
      "                                                                                                                                                                                      grateful       0.95      0.89      0.92      2091\n",
      "                                                                                                                                                                                        guilty       0.77      0.87      0.82      2053\n",
      "                                                                                                                                                                                       hopeful       0.93      0.85      0.89      2019\n",
      "                                                                                                                                                                                     impressed       0.94      0.87      0.91      2004\n",
      "                                                                                                                                                                                       jealous       0.98      0.96      0.97      1955\n",
      "                                                                                                                                                                                        joyful       0.86      0.61      0.71      1953\n",
      "                                                                                                                                                                                        lonely       0.97      0.94      0.96      2106\n",
      "                                                                                                                  m so mad with my brother. He stole from me and didn't think I would notice.        0.00      0.00      0.00         3\n",
      "                                                                                                                                                                                     nostalgic       0.91      0.90      0.90      1996\n",
      "                                                                                                                                                                                      prepared       0.97      0.90      0.93      1937\n",
      "                                                                                                                                                                                         proud       0.91      0.87      0.89      2247\n",
      "                                                                                                                                                                                           sad       0.89      0.58      0.70      2213\n",
      "                                                                                                                                                                                   sentimental       0.92      0.75      0.82      1773\n",
      "                                                                                                                                                                                     surprised       0.97      0.90      0.93      3295\n",
      "                                                                                                              t believe I like the show Power so much. I was never really into shows like that       0.00      0.00      0.00         4\n",
      "                                                                                                                    t believe my daughter taught herself how to play the ukelele. I was amazed       0.00      0.00      0.00         5\n",
      "                                                                                                                                                                      t even like scary things       0.00      0.00      0.00         5\n",
      "                                                                                                                                                              t think I wold like super heroes       0.00      0.00      0.00         4\n",
      "                                                                                                                                                                                     terrified       0.94      0.02      0.04      2074\n",
      "                                                                                                                                                                                      trusting       0.96      0.90      0.93      1755\n",
      "                                                                                                                                                                                       unknown       0.00      0.00      0.00         4\n",
      "\n",
      "                                                                                                                                                                                     micro avg       0.93      0.68      0.78     64636\n",
      "                                                                                                                                                                                     macro avg       0.67      0.49      0.53     64636\n",
      "                                                                                                                                                                                  weighted avg       0.93      0.68      0.72     64636\n",
      "                                                                                                                                                                                   samples avg       0.68      0.68      0.68     64636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "preds_output = trainer.predict(tokenized)\n",
    "pred_labels = (preds_output.predictions > 0.5).astype(int)\n",
    "true_labels = np.array(preds_output.label_ids)\n",
    "\n",
    "# Evaluation report\n",
    "print(classification_report(true_labels, pred_labels, target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93140a91-1299-4800-a047-539664ac97ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saved_roberta_emotion_model-v1/tokenizer_config.json',\n",
       " 'saved_roberta_emotion_model-v1/special_tokens_map.json',\n",
       " 'saved_roberta_emotion_model-v1/vocab.json',\n",
       " 'saved_roberta_emotion_model-v1/merges.txt',\n",
       " 'saved_roberta_emotion_model-v1/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"saved_roberta_emotion_model-v1\")\n",
    "tokenizer.save_pretrained(\"saved_roberta_emotion_model-v1\")\n",
    "# from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "# model = RobertaForSequenceClassification.from_pretrained(\"saved_roberta_emotion_model\")\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"saved_roberta_emotion_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef602f0-b0eb-4ee6-a44b-08ef3fa1d2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed84e08-0fa0-4f5c-bab7-31a261cc3c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned RoBERTa emotion classifier...\n",
      "Loading intent patterns from KB.json...\n",
      "Loading Sentence-BERT model for intent classification...\n",
      "Evaluating intent model self-match accuracy...\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# NLP Mental Health Chatbot - Final Version (Based on Project Proposal)\n",
    "# Emotion Detection: Fine-tuned RoBERTa\n",
    "# Intent Detection: Sentence-BERT + Semantic Matching\n",
    "# Response Generation: LLaMA2 via Ollama\n",
    "# ======================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib\n",
    "\n",
    "# Set environment to suppress warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"MallocStackLogging\"] = \"0\"\n",
    "\n",
    "# ============ STEP 1: Load Fine-Tuned RoBERTa Emotion Model ============\n",
    "print(\"Loading fine-tuned RoBERTa emotion classifier...\")\n",
    "emotion_model = RobertaForSequenceClassification.from_pretrained(\"saved_roberta_emotion_model-v1\")\n",
    "emotion_tokenizer = RobertaTokenizer.from_pretrained(\"saved_roberta_emotion_model-v1\")\n",
    "mlb_classes = joblib.load(\"emotion_labels.pkl\")\n",
    "\n",
    "# ============ STEP 2: Load Sentence-BERT for Intent Detection ============\n",
    "print(\"Loading intent patterns from KB.json...\")\n",
    "with open(\"KB.json\", \"r\") as f:\n",
    "    kb = json.load(f)\n",
    "\n",
    "intent_patterns = []\n",
    "intent_tags = []\n",
    "for intent in kb[\"intents\"]:\n",
    "    tag = intent[\"tag\"]\n",
    "    for pattern in intent.get(\"patterns\", []):\n",
    "        if pattern.strip():\n",
    "            intent_patterns.append(pattern.strip())\n",
    "            intent_tags.append(tag)\n",
    "\n",
    "print(\"Loading Sentence-BERT model for intent classification...\")\n",
    "intent_encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "intent_embeddings = intent_encoder.encode(intent_patterns)\n",
    "\n",
    "# Optional: Evaluate self-accuracy\n",
    "print(\"Evaluating intent model self-match accuracy...\")\n",
    "y_true = intent_tags\n",
    "y_pred = []\n",
    "for pattern in intent_patterns:\n",
    "    input_embedding = intent_encoder.encode([pattern])\n",
    "    sims = cosine_similarity(input_embedding, intent_embeddings)[0]\n",
    "    best_index = sims.argsort()[-1]\n",
    "    y_pred.append(intent_tags[best_index])\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Self-match intent accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# ============ STEP 3: Define Utility Functions ============\n",
    "\n",
    "def detect_emotion_roberta(text):\n",
    "    inputs = emotion_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = emotion_model(**inputs).logits\n",
    "    probs = torch.sigmoid(logits)[0].cpu().numpy()\n",
    "\n",
    "    # Debug print: Show emotion probabilities and mapping\n",
    "    print(\"Raw Emotion Probabilities:\")\n",
    "    for i, p in enumerate(probs):\n",
    "        print(f\"{mlb_classes[i]}: {p:.3f}\")\n",
    "\n",
    "    threshold = 0.35  # Lowered threshold to capture more subtle emotions\n",
    "    top_labels = [mlb_classes[i] for i, p in enumerate(probs) if p > threshold]\n",
    "\n",
    "    if not top_labels:\n",
    "        top_labels = [mlb_classes[int(np.argmax(probs))]]  # fallback if no emotion passes threshold\n",
    "\n",
    "    return top_labels  # fallback if no score > 0.5\n",
    "\n",
    "def detect_intent(text, top_k=3):\n",
    "    \"\"\"Use Sentence-BERT + cosine similarity to detect closest intent.\"\"\"\n",
    "    input_embedding = intent_encoder.encode([text])\n",
    "    sims = cosine_similarity(input_embedding, intent_embeddings)[0]\n",
    "    top_indices = sims.argsort()[-top_k:][::-1]\n",
    "    top_matches = [(intent_tags[i], intent_patterns[i], sims[i]) for i in top_indices]\n",
    "    print(\"Top intent matches:\")\n",
    "    for tag, pattern, score in top_matches:\n",
    "        print(f\" - {tag}: '{pattern}' ({score:.2f})\")\n",
    "    return top_matches[0][0]\n",
    "\n",
    "def llama_respond(prompt: str, model: str = \"llama2\"):\n",
    "    \"\"\"Generate a response using LLaMA2 via Ollama CLI.\"\"\"\n",
    "    try:\n",
    "        print(\"Calling LLaMA2 via Ollama...\")\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", model, prompt],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=180\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return result.stdout.strip()\n",
    "        else:\n",
    "            print(\"Ollama error:\", result.stderr)\n",
    "            return \"I'm sorry, I encountered an issue generating a response.\"\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \"The response took too long to generate. Try again.\"\n",
    "\n",
    "def generate_response(user_input, history=[]):\n",
    "    \"\"\"Pipeline: Detect intent + emotion → generate response using KB and LLaMA2.\"\"\"\n",
    "    emotions = detect_emotion_roberta(user_input)\n",
    "    intent = detect_intent(user_input)\n",
    "\n",
    "    # Try rule-based KB response first\n",
    "    kb_response = None\n",
    "    for entry in kb[\"intents\"]:\n",
    "        if entry[\"tag\"] == intent and entry.get(\"responses\"):\n",
    "            kb_response = entry[\"responses\"]\n",
    "            break\n",
    "\n",
    "    # Add to history\n",
    "    history.append({\"input\": user_input, \"intent\": intent, \"emotions\": emotions})\n",
    "\n",
    "    print(\"--- Debug Info ---\")\n",
    "    print(f\"Detected Emotion(s): {emotions}\")\n",
    "    print(f\"Detected Intent: {intent}\")\n",
    "\n",
    "    # Generate LLaMA2 continuation even if KB exists\n",
    "    prompt_history = \"\".join([f\"User: {msg['input']}Intent: {msg['intent']}Emotion(s): {msg['emotions']}\"\n",
    "        for msg in history[-3:]  ])\n",
    "    prompt = (f\"Context:{prompt_history}\"f\"Now, respond empathetically and constructively to the last user message.\")\n",
    "\n",
    "    if kb_response:\n",
    "        selected_response = kb_response[0] if isinstance(kb_response, list) else kb_response\n",
    "        print(f\"Using KB-based response: {selected_response}\")\n",
    "        print(\"Prompt sent to LLaMA2:\")\n",
    "        print(prompt)\n",
    "        print(\"------------------\")\n",
    "        bot_response = llama_respond(prompt)\n",
    "        return f\"{selected_response}{bot_response}\"\n",
    "    else:\n",
    "        print(\"Prompt sent to LLaMA2:\")\n",
    "        print(prompt)\n",
    "        print(\"------------------\")\n",
    "        return llama_respond(prompt)\n",
    "\n",
    "# ============ STEP 4: CLI Chatbot ============\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the Mental Health Chatbot 💬 (type 'quit' to exit)\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"Bot: Take care! 💙\")\n",
    "            break\n",
    "        response = generate_response(user_input)\n",
    "        print(f\"Bot: {response}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
